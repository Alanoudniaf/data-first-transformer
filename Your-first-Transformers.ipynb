{"cells":[{"cell_type":"markdown","metadata":{"id":"U_jXX6GaW6dP"},"source":["## Introduction to the Transformers Library (Colab Recommended) ğŸ¤—\n","\n","\n","To recap, HuggingFace is an AI company that has blown up in the last few years, especially in the realm of Natural Language Processing (NLP).\n","\n","In particular, the Transformers library has revolutionized the way people  work with large-scale transformer models. The goal of this challenge is to introduce you to these models for the first time and show how easy they can be to work with.\n","\n","### Why you should love HuggingFace:\n","\n","#### Pre-trained Models ğŸ“š:\n","\n","One of the best features of the Transformers library is its huge repo of pre-trained models. Whether you're looking to employ BERT, GPT-2, T5, RoBERTa, or any of the other transformer architectures, chances are you'll find a version that suits your needs in their model hub.\n","\n","#### It's super easy ğŸ‘:\n","\n","The library is designed to be user-friendly. Loading a model and its corresponding tokenizer can be done in just a couple of lines of code. This simplicity extends to fine-tuning as well, allowing you to adapt these powerful models to a wide range of tasks. The `pipelines` library we'll be using lets you go from model selection to getting results in just a few lines.\n","\n","#### Tokenizer  ğŸ”„ and Datasets ğŸ“Š Library:\n","\n","Alongside the Transformers library, HuggingFace also offers the Tokenizers and Datasets libraries. While the first provides efficient and easy-to-use tokenization methods, the second offers a whole bunch of datasets, meaning you have all the tools and data you need in one ecosystem.\n","\n","#### Community-Driven ğŸŒ:\n","The HuggingFace community is very active and any community member (you included) can upload their own models and datasets."],"id":"U_jXX6GaW6dP"},{"cell_type":"markdown","metadata":{"id":"KkmuxZUKW6dT"},"source":["__If you are working in Colab__ you'll need to install the appropriate libraries in your Colab environment (you will have them locally if you followed the setup instructions)"],"id":"KkmuxZUKW6dT"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvXM4xaMW6dT","executionInfo":{"status":"ok","timestamp":1744548021498,"user_tz":-180,"elapsed":107913,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"43b8847a-6b04-451c-d0a6-00d11042c777"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n","Installing collected packages: pytesseract, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytesseract-0.3.13\n"]}],"source":["# Install the transformers library from HuggingFace\n","!pip install transformers torch pytesseract"],"id":"VvXM4xaMW6dT"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9W6Dd-xW6dU","executionInfo":{"status":"ok","timestamp":1744548025230,"user_tz":-180,"elapsed":3711,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"6844e592-4e29-44d0-af77-75e266c66084"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses) (2024.11.6)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.4.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses) (4.67.1)\n","Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sacremoses\n","Successfully installed sacremoses-0.1.1\n"]}],"source":["# You'll also need some extra tools that some of these models use under the hood\n","! pip install sentencepiece sacremoses"],"id":"K9W6Dd-xW6dU"},{"cell_type":"markdown","metadata":{"id":"IfSq2TqYW6dV"},"source":["Over the course of this notebook, you'll be using Pipelines to download and easily use some very powerful models. Bear in mind that some of these models are quite large (up to 500Mb so make sure you have some disk space free on your machine or run this notebook in a Colab with faster download speeds!).\n","\n","We are going to be using pre-built models and the best resource for implementing them will be using the [Pipelines documentation](https://huggingface.co/docs/transformers/main_classes/pipelines). If you ever want to delete the models locally after use, you can find them here in your root directory at:\n","\n","`/.cache/huggingface/hub`"],"id":"IfSq2TqYW6dV"},{"cell_type":"markdown","metadata":{"id":"OCovwg6MW6dV"},"source":["### Basic Sentiment : ğŸ˜€ /  ğŸ˜• / ğŸ˜  / ğŸ˜Ÿ"],"id":"OCovwg6MW6dV"},{"cell_type":"markdown","metadata":{"id":"wdJ5lV75W6dV"},"source":["With that in mind, instantiate a pipeline for sentiment analysis __without__ specifying a model and try testing out that model with the sentence \"Transformers are awesome!\" Feel free to try some other sentences, too."],"id":"wdJ5lV75W6dV"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBpe9aLEW6dV","executionInfo":{"status":"ok","timestamp":1744548052366,"user_tz":-180,"elapsed":25913,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"04820cbc-4751-4364-ed73-9061cff0524a"},"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["Transformers are awesome! POSITIVE ğŸ˜€\n"," 99.99%\n","\n","This code keeps giving me errors NEGATIVE ğŸ˜Ÿ\n"," 99.97%\n","\n"]}],"source":["pass  # YOUR CODE HERE\n","from transformers import pipeline\n","model = pipeline(\"sentiment-analysis\")\n","\n","sentences = [\n","    \"Transformers are awesome!\",\n","    \"This code keeps giving me errors\"\n","]\n","\n","results = model(sentences)\n","\n","state = {\n","    \"POSITIVE\": \"ğŸ˜€\",\n","    \"NEGATIVE\": \"ğŸ˜Ÿ\",\n","    \"NEUTRAL\": \"ğŸ˜\"\n","}\n","\n","for text, result in zip(sentences, results):\n","    print(f\"{text} {result['label']} {state.get(result['label'], '')}\")\n","    print(f\" {result['score']:.2%}\\n\")\n"],"id":"zBpe9aLEW6dV"},{"cell_type":"markdown","metadata":{"id":"4tkCcqU_W6dV"},"source":["### Nuanced Sentiment ğŸ¤”"],"id":"4tkCcqU_W6dV"},{"cell_type":"markdown","metadata":{"id":"9rCRIN7kW6dW"},"source":["HuggingFace will default to using `distilbert-base-uncased-finetuned-sst-2-english` if we don't specify a model. This model will work fine on a lot of basic use cases, but - because it's been trained on a fairly limited corpus of text:\n","\n","`The Stanford Sentiment Treebank is a corpus with fully labeled parse trees that allows for a complete analysis of the compositional effects of sentiment in language. The corpus is based on the dataset introduced by Pang and Lee (2005) and consists of 11,855 single sentences extracted from movie reviews. It was parsed with the Stanford parser and includes a total of 215,154 unique phrases from those parse trees, each annotated by 3 human judges.`\n","\n","It's fairly obvious that a model trained on this will likely perform poorly on sentences that include modern language: e.g. \"These beats are sick!\". Try running these sentences through your pipeline now and you should get negative scores even though they are expressing quite positive sentiment."],"id":"9rCRIN7kW6dW"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sWAQt5zsW6dW","executionInfo":{"status":"ok","timestamp":1744548052977,"user_tz":-180,"elapsed":646,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"96bc9389-a120-4ed8-bd7a-4755a43469e4"},"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["These beats are sick!\n"," NEGATIVE (99.97%)\n","That's whack\n"," NEGATIVE (95.94%)\n","This pizza slaps\n"," NEGATIVE (99.30%)\n"]}],"source":["pass  # YOUR CODE HERE\n","from transformers import pipeline\n","way = pipeline(\"sentiment-analysis\")\n","\n","texts = [\n","    \"These beats are sick!\",\n","    \"That's whack\",\n","    \"This pizza slaps\"\n","]\n","for text in texts:\n","    result = way(text)[0]\n","    print(text)\n","    print(f\" {result['label']} ({result['score']:.2%})\")"],"id":"sWAQt5zsW6dW"},{"cell_type":"markdown","metadata":{"id":"B59SOtAbW6dW"},"source":["Go to the list of HuggingFace models to see if you can find a model that will specialize on Twitter sentiment (looking for `\"twitter-roberta-base-sentiment-latest\"` might be a good place to start) - hopefully that should be a bit more up to date with all this new lingo! Now create a second pipeline, this time __specifying__ that model that we want to use (use `model=`) and see how our performance instantly improves now we're using a fine-tuned model.\n"],"id":"B59SOtAbW6dW"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R39TCzMBW6dW","executionInfo":{"status":"ok","timestamp":1744548058178,"user_tz":-180,"elapsed":5200,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"baa1c62f-94d8-4efa-e766-a8fb3b8639f7"},"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cuda:0\n","Device set to use cuda:0\n"]}],"source":["pass  # YOUR CODE HERE\n","model = pipeline(\"sentiment-analysis\")\n","twitter = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")"],"id":"R39TCzMBW6dW"},{"cell_type":"code","source":["test_model = [\n","    \"I love data seince\",\n","    \"What a wondeful naight\",\n","    \"I hate late nights\"\n","]"],"metadata":{"id":"8P_58diXtVd1","executionInfo":{"status":"ok","timestamp":1744548058197,"user_tz":-180,"elapsed":4,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}}},"id":"8P_58diXtVd1","execution_count":6,"outputs":[]},{"cell_type":"code","source":["for text in test_model:\n","    print(f\"{text}\")\n","    print(f\"{model(text)[0]}\")\n","    print(f\"{twitter(text)[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMIrX078uFje","executionInfo":{"status":"ok","timestamp":1744548058674,"user_tz":-180,"elapsed":464,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"2cb489b5-04dc-45fa-b5a6-331518a3ef79"},"id":"lMIrX078uFje","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["I love data seince\n","{'label': 'POSITIVE', 'score': 0.9996283054351807}\n","{'label': 'LABEL_2', 'score': 0.9697285890579224}\n","What a wondeful naight\n","{'label': 'POSITIVE', 'score': 0.9899623394012451}\n","{'label': 'LABEL_2', 'score': 0.6254957318305969}\n","I hate late nights\n","{'label': 'NEGATIVE', 'score': 0.9945341348648071}\n","{'label': 'LABEL_0', 'score': 0.9483242630958557}\n"]}]},{"cell_type":"markdown","metadata":{"id":"THxgYuaTW6dW"},"source":["You should see a much more accurate interpretation of the sentiment we're trying to express."],"id":"THxgYuaTW6dW"},{"cell_type":"markdown","metadata":{"id":"AIIfx2D-W6dW"},"source":["### Sentiment in other languages"],"id":"AIIfx2D-W6dW"},{"cell_type":"markdown","metadata":{"id":"cmW8ZblZW6dW"},"source":["While even our first pipeline will actually perform surprisingly well on simple sentences in other languages (e.g. \"C' est bon\" or \"Esta bueno\"), it breaks down when handling more sophisticated ideas in those languages."],"id":"cmW8ZblZW6dW"},{"cell_type":"markdown","metadata":{"id":"gjKrJfSCW6dX"},"source":["Here is an example review for the Jurassic World Dominion movie ğŸ˜¬:\n","\n","\"This was frankly a spectacular failure from start to finish, with  remarkably uninspired performances from some very well-paid actors who acted with all the passion of a wet biscuit\""],"id":"gjKrJfSCW6dX"},{"cell_type":"markdown","metadata":{"id":"qwgeC9A9W6dX"},"source":["Tranlated into Korean it reads as this: \"ì´ê²ƒì€ ì†”ì§íˆ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì—„ì²­ë‚œ ì‹¤íŒ¨ì˜€ìœ¼ë©° ì –ì€ ë¹„ìŠ¤í‚·ì˜ ëª¨ë“  ì—´ì •ìœ¼ë¡œ ì—°ê¸°í•œ ì¼ë¶€ ë§¤ìš° ë³´ìˆ˜ê°€ ì¢‹ì€ ë°°ìš°ë“¤ì˜ í˜„ì €í•˜ê²Œ ì˜ê°ì„ ë°›ì§€ ëª»í•œ ì—°ê¸°ë¡œ ëë‚¬ìŠµë‹ˆë‹¤.\""],"id":"qwgeC9A9W6dX"},{"cell_type":"markdown","metadata":{"id":"qOPgS5tSW6dX"},"source":["Try running the Korean text through either your Twitter model; you should see they won't pick up on how bad the review is."],"id":"qOPgS5tSW6dX"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"Kr2QwNH6W6dX","executionInfo":{"status":"ok","timestamp":1744548064138,"user_tz":-180,"elapsed":5463,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"658b132f-7097-4ef5-be82-98c7114fde1f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"execute_result","data":{"text/plain":["'It was a huge failure, frankly, from beginning to end, and it ended up with some of the most conservative actors who played it with all the passion of wet biscuits, obviously uninspired.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["pass  # YOUR CODE HERE\n","pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ko-en\")\n","result = pipe(\"ì´ê²ƒì€ ì†”ì§íˆ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì—„ì²­ë‚œ ì‹¤íŒ¨ì˜€ìœ¼ë©° ì –ì€ ë¹„ìŠ¤í‚·ì˜ ëª¨ë“  ì—´ì •ìœ¼ë¡œ ì—°ê¸°í•œ ì¼ë¶€ ë§¤ìš° ë³´ìˆ˜ê°€ ì¢‹ì€ ë°°ìš°ë“¤ì˜ í˜„ì €í•˜ê²Œ ì˜ê°ì„ ë°›ì§€ ëª»í•œ ì—°ê¸°ë¡œ ëë‚¬ìŠµë‹ˆë‹¤\")\n","result[0]['translation_text']"],"id":"Kr2QwNH6W6dX"},{"cell_type":"markdown","metadata":{"id":"cMH8axAgW6dX"},"source":["Now see if you can find a model that might perform better in the HuggingFace library and use it. Try using `\"matthewburke/korean_sentiment\"` in a `text-classification` pipeline and see if your results change."],"id":"cMH8axAgW6dX"},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8zGantlW6dX","executionInfo":{"status":"ok","timestamp":1744548064887,"user_tz":-180,"elapsed":769,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"990494a2-5723-4481-bdec-2c3857b4e081"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["Translated text: {'label': 'LABEL_0', 'score': 0.9602949023246765}\n"]}],"source":["pass  # YOUR CODE HERE\n","pipe = pipeline(\"text-classification\",\n","                model=\"matthewburke/korean_sentiment\")\n","\n","result = pipe(\"ì´ê²ƒì€ ì†”ì§íˆ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì—„ì²­ë‚œ ì‹¤íŒ¨ì˜€ìœ¼ë©° ì –ì€ ë¹„ìŠ¤í‚·ì˜ ëª¨ë“  ì—´ì •ìœ¼ë¡œ ì—°ê¸°í•œ ì¼ë¶€ ë§¤ìš° ë³´ìˆ˜ê°€ ì¢‹ì€ ë°°ìš°ë“¤ì˜ í˜„ì €í•˜ê²Œ ì˜ê°ì„ ë°›ì§€ ëª»í•œ ì—°ê¸°ë¡œ ëë‚¬ìŠµë‹ˆë‹¤\")\n","print(\"Translated text:\", result[0])"],"id":"-8zGantlW6dX"},{"cell_type":"code","source":["pass  # YOUR CODE HERE\n","pipe = pipeline(\"translation\",\n","                model=\"DunnBC22/opus-mt-ko-en-Korean_Parallel_Corpora\")\n","\n","result = pipe(\"ì´ê²ƒì€ ì†”ì§íˆ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì—„ì²­ë‚œ ì‹¤íŒ¨ì˜€ìœ¼ë©° ì –ì€ ë¹„ìŠ¤í‚·ì˜ ëª¨ë“  ì—´ì •ìœ¼ë¡œ ì—°ê¸°í•œ ì¼ë¶€ ë§¤ìš° ë³´ìˆ˜ê°€ ì¢‹ì€ ë°°ìš°ë“¤ì˜ í˜„ì €í•˜ê²Œ ì˜ê°ì„ ë°›ì§€ ëª»í•œ ì—°ê¸°ë¡œ ëë‚¬ìŠµë‹ˆë‹¤\")\n","print(\"Translated text:\", result[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-PbE31KzhLC","executionInfo":{"status":"ok","timestamp":1744548068245,"user_tz":-180,"elapsed":3208,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"bc9e2394-1e15-4491-d946-8de1d250af1e"},"id":"b-PbE31KzhLC","execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["Translated text: {'translation_text': 'It was a huge failure from beginning to end, frankly, and ended with some of the very conservative actors who played with all the passion of the wet Biscuit, which was largely uninspired.'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"2QSN78JrW6dX"},"source":["### Translation âœï¸"],"id":"2QSN78JrW6dX"},{"cell_type":"markdown","metadata":{"id":"Pyqbp8XzW6dX"},"source":["Let's stick with our language theme and see if we can find a model that can handle the tasks of translating some sentences for us. The `opus-mt` project from the University of Helsinki is incredibly active on HuggingFace, creating and maintaining models designed to democratize the translation process for many different global languages. Try implementing the `\"Helsinki-NLP/opus-mt-<source-language>-<destination-language>\"` to see if you can translate between two langauges (e.g. English to Spanish)."],"id":"Pyqbp8XzW6dX"},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7H6NYi9GW6dX","executionInfo":{"status":"ok","timestamp":1744548183003,"user_tz":-180,"elapsed":6019,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"36ef07ef-c979-4e70-d6be-ddb88cb17038"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["Buenos dÃ­as.\n"]}],"source":["pass  # YOUR CODE HERE\n","from transformers import pipeline\n","\n","summarizer = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n","print(summarizer(\"Good morining\")[0]['translation_text'])"],"id":"7H6NYi9GW6dX"},{"cell_type":"markdown","metadata":{"id":"ePd8xVHyW6dX"},"source":["### Summarization"],"id":"ePd8xVHyW6dX"},{"cell_type":"markdown","metadata":{"id":"zcaxSO5rW6dX"},"source":["Another really useful NLP task is summarizing a large amount of information into a very small amount of words. BART is a model that performs well on tasks like summarization; it contains a combination of two models you've already seen briefly in the lecture - the BERT model and autogressive style GPT model - check out this [link](https://www.projectpro.io/article/transformers-bart-model-explained/553) for some more information on it.\n","\n","Since BART models can be quite large, try to find the `distilbart-xsum-12-6` model on HuggingFace which is one of the smallest distillations available (we'll talk more about distillations later!). Integrate that model into a `\"summarization\"` pipeline, then take some text (e.g. perhaps by copy-pasting [a BBC article](https://www.bbc.com/news/topics/cx2pk70323et)) and summarize it with your pipeline!\n","\n","N.B. You need to be careful about context windows - here, you may run into an issue with your input being too long for the model!"],"id":"zcaxSO5rW6dX"},{"cell_type":"code","execution_count":15,"metadata":{"id":"XXkQcWljW6dX","executionInfo":{"status":"ok","timestamp":1744548186421,"user_tz":-180,"elapsed":3,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}}},"outputs":[],"source":["text = \"\"\"\n","If you can dreamâ€”and not make dreams your master;\n","If you can thinkâ€”and not make thoughts your aim;\n","If you can meet with Triumph and Disaster\n","And treat those two impostors just the same;\n","If you can bear to hear the truth youâ€™ve spoken\n","Twisted by knaves to make a trap for fools,\n","Or watch the things you gave your life to, broken,\n","And stoop and build â€™em up with worn-out tools\n","\"\"\""],"id":"XXkQcWljW6dX"},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hd4AMHpHW6dY","executionInfo":{"status":"ok","timestamp":1744548310620,"user_tz":-180,"elapsed":4369,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"ffa7b681-a961-463f-eeef-44905f4d4e2c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["{'summary_text': ' If you can bear to hear the truth youâ€™ve spoken, or watch the things you gave your life to, broken, or stoop and build â€˜em up with worn-out toolsâ€™'}\n"]}],"source":["pass  # YOUR CODE HERE\n","from transformers import pipeline\n","summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n","summary = summarizer(text, max_length=100, min_length=30, do_sample=False)\n","print(summary[0])"],"id":"Hd4AMHpHW6dY"},{"cell_type":"markdown","metadata":{"id":"pDQEJPmFW6dY"},"source":["### Going further: Question Answering ğŸ”"],"id":"pDQEJPmFW6dY"},{"cell_type":"markdown","metadata":{"id":"YD76vA6eW6dY"},"source":["What if we wanted to go further than just a summary? Perhaps asking questions about a specific dataset in an intuitive way? There's a model for that, too! Enter the (reasonably small) `roberta-base-squad2` - a model trained on question-answer pairs that can answer a `question` about a provided `context` (a body of text you will provide). Check the docs [here](https://huggingface.co/deepset/roberta-base-squad2?context=The+Amazon+rainforest+%28Portuguese%3A+Floresta+Amaz%C3%B4nica+or+Amaz%C3%B4nia%3B+Spanish%3A+Selva+Amaz%C3%B3nica%2C+Amazon%C3%ADa+or+usually+Amazonia%3B+French%3A+For%C3%AAt+amazonienne%3B+Dutch%3A+Amazoneregenwoud%29%2C+also+known+in+English+as+Amazonia+or+the+Amazon+Jungle%2C+is+a+moist+broadleaf+forest+that+covers+most+of+the+Amazon+basin+of+South+America.+This+basin+encompasses+7%2C000%2C000+square+kilometres+%282%2C700%2C000+sq+mi%29%2C+of+which+5%2C500%2C000+square+kilometres+%282%2C100%2C000+sq+mi%29+are+covered+by+the+rainforest.+This+region+includes+territory+belonging+to+nine+nations.+The+majority+of+the+forest+is+contained+within+Brazil%2C+with+60%25+of+the+rainforest%2C+followed+by+Peru+with+13%25%2C+Colombia+with+10%25%2C+and+with+minor+amounts+in+Venezuela%2C+Ecuador%2C+Bolivia%2C+Guyana%2C+Suriname+and+French+Guiana.+States+or+departments+in+four+nations+contain+%22Amazonas%22+in+their+names.+The+Amazon+represents+over+half+of+the+planet%27s+remaining+rainforests%2C+and+comprises+the+largest+and+most+biodiverse+tract+of+tropical+rainforest+in+the+world%2C+with+an+estimated+390+billion+individual+trees+divided+into+16%2C000+species.&question=How+many+species+are+in+the+Amazon%3F)."],"id":"YD76vA6eW6dY"},{"cell_type":"markdown","metadata":{"id":"G-cqeqTHW6dY"},"source":["You know the drill: Create a `\"question-answering\"` pipeline with the `roberta-base-squad2` model, then try putting the `article` you picked before as your context and try asking a `question` about it."],"id":"G-cqeqTHW6dY"},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oKY1np1wW6dY","executionInfo":{"status":"ok","timestamp":1744548320207,"user_tz":-180,"elapsed":4592,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"5870a7cc-2071-4288-9df7-cda621fb23c4"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}],"source":["pass  # YOUR CODE HERE\n","Qanswering = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")"],"id":"oKY1np1wW6dY"},{"cell_type":"code","source":["context = \"\"\"\n","All things in life pass away, except what we create from our soul.\n","People chase after money and status,\n","but the artist seeks only truth.\n","A personâ€™s finest moments are those spent listening to their inner voice,\n","when what they paint or write becomes their true self, not a mirror of othersâ€™ desires\n","\"\"\""],"metadata":{"id":"2ybg5V2ZAcH7","executionInfo":{"status":"ok","timestamp":1744548321888,"user_tz":-180,"elapsed":11,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}}},"id":"2ybg5V2ZAcH7","execution_count":21,"outputs":[]},{"cell_type":"code","source":["questions = [\n","    \"What is the only thing that doesn't pass away?\",\n","    \"What do ordinary people chase?\",\n","    \"What does the artist seek?\",\n","    \"When are a person's finest moments?\",\n","    \"What becomes an artist's true self?\"\n","]"],"metadata":{"id":"zgY-5WBmBaKN","executionInfo":{"status":"ok","timestamp":1744548323587,"user_tz":-180,"elapsed":13,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}}},"id":"zgY-5WBmBaKN","execution_count":22,"outputs":[]},{"cell_type":"code","source":["print(\"=== PHILOSOPHICAL QA ===\")\n","for question in questions:\n","    answer = Qanswering(question=question, context=context)\n","    print(f\"Q: {question}\")\n","    print(f\"A: {answer['answer']} (confidence: {answer['score']:.0%})\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0uP04W_Bgdl","executionInfo":{"status":"ok","timestamp":1744548325751,"user_tz":-180,"elapsed":99,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"4e7b7cf9-5f9f-42c4-f901-a79a0add4c85"},"id":"s0uP04W_Bgdl","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["=== PHILOSOPHICAL QA ===\n","Q: What is the only thing that doesn't pass away?\n","A: what we create from our soul (confidence: 41%)\n","\n","Q: What do ordinary people chase?\n","A: money and status (confidence: 68%)\n","\n","Q: What does the artist seek?\n","A: truth (confidence: 79%)\n","\n","Q: When are a person's finest moments?\n","A: listening to their inner voice (confidence: 16%)\n","\n","Q: What becomes an artist's true self?\n","A: what they paint or write (confidence: 42%)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"hnwcAPxLW6dY"},"source":["### Speech to text ğŸ¤"],"id":"hnwcAPxLW6dY"},{"cell_type":"markdown","metadata":{"id":"cmwmjrFJW6dY"},"source":["One of the best models for converting speech to text was made is the open source Whisper model made by OpenAI (creator of ChatGPT etc.) Take a look at the diagram of the model architecture - it should now look quite similar to those you've already seen today:\n","\n","\n","<img src = https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/whipser.png width = 450px>"],"id":"cmwmjrFJW6dY"},{"cell_type":"markdown","metadata":{"id":"3kxfFhlbW6dY"},"source":["Run the following command to download this audio sample and install some additional required packages:"],"id":"3kxfFhlbW6dY"},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sOxiH_q5W6dY","executionInfo":{"status":"ok","timestamp":1744548332915,"user_tz":-180,"elapsed":2346,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"ecd8599d-45c8-4786-fdda-630959394ef3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"]}],"source":["# # line below for Windows/ Linux/ Colab\n","!sudo apt install ffmpeg\n","\n","# Uncomment line below for Mac users\n","# !HOMEBREW_NO_AUTO_UPDATE=1 brew install ffmpeg"],"id":"sOxiH_q5W6dY"},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPF12FIZW6dY","executionInfo":{"status":"ok","timestamp":1744548338684,"user_tz":-180,"elapsed":2179,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"afbf8aae-15e8-42ce-cdbc-7b3dd62d9134"},"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory â€˜dataâ€™: File exists\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 3173k  100 3173k    0     0  1688k      0  0:00:01  0:00:01 --:--:-- 1688k\n"]}],"source":["!mkdir data\n","!curl https://wagon-public-datasets.s3.amazonaws.com/deep_learning_datasets/harvard.wav > data/harvard.wav"],"id":"YPF12FIZW6dY"},{"cell_type":"markdown","metadata":{"id":"MJAQBaS5W6dZ"},"source":["You can listen to the clip by using the by importing `IPython` and loading the audio file (see the Algebra day recap for an example of how this is done!)"],"id":"MJAQBaS5W6dZ"},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75,"output_embedded_package_id":"1-wVORoOyNk7Pm9DWA3q7l7XR0Rza4fSe"},"id":"Khl36TkbW6dc","executionInfo":{"status":"ok","timestamp":1744548341629,"user_tz":-180,"elapsed":1282,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"8eb7f5dd-d273-4e65-8854-369ffd2ab878"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["pass  # YOUR CODE HERE\n","import IPython\n","IPython.display.Audio(\"data/harvard.wav\")"],"id":"Khl36TkbW6dc"},{"cell_type":"markdown","metadata":{"id":"eLRi3wrlW6dd"},"source":["Find the smallest Whisper model version on HuggingFace (`whisper-tiny`) and use it to transcribe the audio. Try it on some other `.wav` files if you'd like!"],"id":"eLRi3wrlW6dd"},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpIpP1MkW6dd","executionInfo":{"status":"ok","timestamp":1744548346667,"user_tz":-180,"elapsed":3144,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"c257d0cd-99d8-427c-a567-cbe1219903ef"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n","/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n","  warnings.warn(\n","Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"]},{"output_type":"stream","name":"stdout","text":[" The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health in zest. A salt pickle tastes fine with ham. Tacos all pastora are my favorite. A zestful food is the hot cross bun.\n"]}],"source":["pass  # YOUR CODE HERE\n","from transformers import pipeline\n","\n","transcribe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-tiny\")\n","\n","result = transcribe(\"data/harvard.wav\")\n","print(result[\"text\"])\n","# haraaaaaaammmmm"],"id":"tpIpP1MkW6dd"},{"cell_type":"markdown","metadata":{"id":"7JkAwBulW6dd"},"source":["### Bonus: Let's get multimodal ğŸ˜: Visual Question Answering"],"id":"7JkAwBulW6dd"},{"cell_type":"markdown","metadata":{"id":"xhMZiIGPW6dd"},"source":["We can even use question-answering style models on images if we'd like. Many of these models will use chains under the hood that will extract text from an image then pass it through to a language model. In order to use the following model you will need to make sure you `pip install Pillow pytesseract` which are two libraries that will help us to extract text from our images.\n","\n","Once that's done, we're going to create a `\"document-question-answering\"` pipeline - we'll need a model for it, so search for the `layoutlm-invoices` model on HuggingFace. Then try to ask questions about this [`receipt.webp`](https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/receipt.webp) (you download the image to your data folder or you can pass the url directly into your model when you call it). Try asking how much the eggs cost, what sales tax was and what the total was. Feel free to try it on some of your own images!"],"id":"xhMZiIGPW6dd"},{"cell_type":"markdown","metadata":{"id":"6BgjAC_rW6dd"},"source":["For this to run, you'll need some dependencies:"],"id":"6BgjAC_rW6dd"},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0vlm5kCW6dd","executionInfo":{"status":"ok","timestamp":1744548355853,"user_tz":-180,"elapsed":5130,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"b5bf9ccd-5162-4786-a382-4d47e59c0bcd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","tesseract-ocr is already the newest version (4.1.1-2.1build1).\n","0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libtesseract-dev is already the newest version (4.1.1-2.1build1).\n","0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"]}],"source":["# For Mac, uncomment:\n","# !brew install tesseract\n","\n","# For Linux or Colab etc. uncomment these:\n","!sudo apt install tesseract-ocr\n","!sudo apt install libtesseract-dev\n","\n","# Then restart your kernel and give it a try!"],"id":"b0vlm5kCW6dd"},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9y1WdhB6W6dd","executionInfo":{"status":"ok","timestamp":1744548358885,"user_tz":-180,"elapsed":639,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"16b99e69-dcb6-4159-ba32-4ea4ee45a640"},"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to impira/layoutlm-document-qa and revision beed3c4 (https://huggingface.co/impira/layoutlm-document-qa).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cuda:0\n"]}],"source":["pass  # YOUR CODE HERE\n","from transformers import pipeline\n","from PIL import Image\n","\n","doc_qa = pipeline(\"document-question-answering\")\n"],"id":"9y1WdhB6W6dd"},{"cell_type":"code","source":["result = doc_qa(\n","    image=Image.open(\"/content/data/receipt.webp\"),\n","    question=\"What is the total amount?\"\n",")\n","\n","print(f\"Total: {result[0]['answer']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iT6CWeqBIyiM","executionInfo":{"status":"ok","timestamp":1744548361433,"user_tz":-180,"elapsed":2545,"user":{"displayName":"Alanoud Naif abdulaziz bin Razin","userId":"11228585971442559443"}},"outputId":"8b3de5db-f036-4130-a552-46f4a128bd10"},"id":"iT6CWeqBIyiM","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Total: $55.59\n"]}]},{"cell_type":"markdown","metadata":{"id":"2m18toM_W6dd"},"source":["Congrats ğŸ‰ You've just seen how simple it can be to start working with some advanced Transformer-based models and we've only just scratched the surface.\n","\n","There are so many models you can explore in the HuggingFace library for all kinds of different tasks. Your imagination is literally the limit (well - your compute power can also be a limit somtimes ğŸ˜…). To take these models even further for custom usage, we're going to tackle fine-tuning next."],"id":"2m18toM_W6dd"},{"cell_type":"markdown","metadata":{"id":"dKViF9u0W6dd"},"source":["âš ï¸âš ï¸âš ï¸ If you have been running these models locally, don't forget to clean up your `/.cache/huggingface/hub` if you're limited on space or you'll have a lot of unwanted models hanging around in your cache ğŸ§¹ âš ï¸âš ï¸âš ï¸"],"id":"dKViF9u0W6dd"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}